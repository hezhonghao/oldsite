<!DOCTYPE html>
<html>
<head>
    <link rel='stylesheet' href='https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap'>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            margin: 10;
            padding-left: 40px;   /* left and right margin */ 
            padding-right: 40px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: left;
            height: 100vh; /* Full height for centering */
            text-align: left;
            padding: 20px;
            box-sizing: border-box;
        }
        p {
            line-height: 1.8;  /* spacing */
            margin: 20px 0; /* Add margin for additional spacing */
        }
        footer {
            position: fixed;
            bottom: 0;
            width: 100%;
            text-align: center;
            padding: 10px;
            background-color: #f1f1f1;
        }
        footer a {
            margin: 0 10px;
            text-decoration: none;
            color: #000;
        }
    </style>
</head>
<body>
<h1>Zhonghao He</h1>
<p>Hi! I am Zhonghao, a master's student at the University of Cambridge.
    I've been working on topics including agentic risks, alignment, interpretability, and neuroscience (upcoming).

    Ultimately, I want to build AIs for human excellence (in Greek conception), which requires both sound societal mechanism design and epistemic tools with which individuals can better exercise their agency.
    A lot of effort is required to operationalize those concepts, but broadly these topics are relevant: mechanistic interpretability, computational neuroscience, AI ethics, alignment, political philosophy, virtue ethics, multi-agent systems, AI for science, and human-computer interface.
</p>

<h2>Research</h2>
You may read my published work on <a href="https://scholar.google.com/citations?user=PuUcZTYAAAAJ&hl=en&oi=ao">Google Scholar.</a>
My current "Hamming Problems" are:
<ul>
    <li>How does knowledge diversity get lost from training and using LLM? (an ongoing <a href]"https://docs.google.com/document/d/167yB9PMSPP5yRnu4_VmWkR3zG0rXRwQApnm5YVNJZag/edit">research aiming for ICLR)</a></li>
    <li>How do we better understand neural networks with mechanistic interpretability, information, and neuroscience?</li>
    <li>What knowledge assistant helps humans to think better?</li>
</ul>

I strive to become a "full stack researcher," which, in my definition, is to have technical sophistication (experiments, mathematics, and engineering) and deep engagements with problems (technical and societal ones). Building technologies for human betterment is hard, and let's get this one right.

Here is <a href="https://docs.google.com/document/d/1lICZ5ftJwZbVLm2f0NockRuwiDryhxRhHEXF4jg76dM/edit">a list of research projects</a> I am interested in working on.

<h2>Contacts</h2>
I love free-flow research conversations! You may simply book a quick call via <a href="">Calendly. </a> (I blocked deep work, sleep, and private time, so don't worry!)
You may drop me a very short email at zh378@cam.ac.uk 

<footer>
    <a href='https://scholar.google.com/citations?user=PuUcZTYAAAAJ&hl=en&oi=ao'>Google Scholar</a> | 
    <a href='https://github.com/hezhonghao'>GitHub</a> | 
    <a href='https://twitter.com/zhonghaohe'>Twitter</a>
</footer>
</body>
</html>